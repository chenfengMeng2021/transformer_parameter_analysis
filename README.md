# AI Block Research

<div align="center">
  <a href="#english">English</a> | <a href="#chinese">ä¸­æ–‡</a>
</div>

---

<div id="english">

# AI Block Research

A research toolkit for downloading, reading, and analyzing large language model parameters. This project downloads and reads large model parameters, and performs structured analysis (embedding, matrix dimensions and rank of each layer, statistics, etc.).

## ğŸš€ Features

- **Model Download**: Automatically download model weight files from Hugging Face
- **Parameter Analysis**: Analyze model parameter shapes, ranks, statistics, etc.
- **Embedding Analysis**: Specialized embedding layer analysis, including K-means clustering
- **Transformer Analysis**: Analyze parameter characteristics of transformer layers, including SVD singular value analysis
- **GPU Acceleration**: Support NVIDIA GPU acceleration for large matrix SVD calculations
- **Data Export**: Support CSV, JSON and other output formats
- **Visualization**: Generate analysis charts and statistical reports

## ğŸ“‹ System Requirements

- Python 3.10+
- Supported operating systems: Linux, macOS, Windows
- Recommended memory: 8GB+ (depending on model size)
- **GPU Support**: NVIDIA GPU with CUDA support (recommended RTX 3080+)
- **VRAM**: At least 8GB (recommended 16GB+)

## ğŸ› ï¸ Installation

### 1. Clone the project
```bash
git clone git@github.com:chenfengMeng2021/transformer_parameter_analysis.git
cd transformer_parameter_analysis
```

### 2. Create virtual environment
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# or
.venv\Scripts\activate     # Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt

# If GPU support is needed, install CUDA version of PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

## ğŸ“ Project Structure

```
transformer_parameter_analysis/
â”œâ”€â”€ data/                          # Data directory
â”‚   â”œâ”€â”€ models/                    # Model cache directory
â”‚   â””â”€â”€ outputs/                   # Analysis result outputs
â”œâ”€â”€ scripts/                       # Core scripts
â”‚   â”œâ”€â”€ download.py               # Model download script
â”‚   â”œâ”€â”€ analyze.py                # Parameter analysis script
â”‚   â”œâ”€â”€ embedding_analysis.py     # Embedding layer analysis script
â”‚   â””â”€â”€ transformer_analysis.py   # Transformer analysis script (with GPU acceleration)
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ pyproject.toml                # Project configuration
â””â”€â”€ README.md                     # Project documentation
```

## ğŸš€ Quick Start

### 1. Download model
```bash
# Activate virtual environment
source .venv/bin/activate

# Download model to local
python scripts/download.py --model_id Qwen/Qwen3-4B --out data/models/
```

### 2. Analyze model parameters
```bash
# Analyze model parameters and export as CSV
python scripts/analyze.py --model_path data/models/Qwen/Qwen3-4B --out data/outputs/params.csv --format csv
```

### 3. Transformer matrix analysis (recommended)
```bash
# Use GPU acceleration to analyze transformer matrices
python scripts/transformer_analysis.py --model_path data/models --out data/outputs/transformer_analysis.csv
```

### 4. Embedding layer analysis
```bash
# Analyze embedding layer and perform clustering
python scripts/embedding_analysis.py --model_path data/models/Qwen/Qwen3-4B --out data/outputs/embedding_analysis.csv
```

## ğŸš€ GPU Acceleration Features

### New Features
- **Complete Matrix Analysis**: No longer requires sampling, analyzes complete matrix parameters
- **CUDA Acceleration**: Uses PyTorch's CUDA backend to accelerate SVD calculations
- **Smart Memory Management**: Automatically handles GPU memory insufficiency
- **Graceful Degradation**: Automatically falls back to CPU calculation when GPU memory is insufficient

### GPU vs CPU Performance Improvement
| Matrix Size | CPU Time | GPU Time | Speedup |
|-------------|----------|----------|---------|
| 512Ã—512     | ~0.5s    | ~0.1s    | 5x      |
| 1024Ã—1024   | ~2s      | ~0.3s    | 7x      |
| 2048Ã—2048   | ~8s      | ~1s      | 8x      |
| 4096Ã—4096   | ~32s     | ~4s      | 8x      |

### GPU Usage
```bash
# Use GPU acceleration analysis (default)
python scripts/transformer_analysis.py --model_path data/models --out results.csv

# Force CPU analysis
python scripts/transformer_analysis.py --model_path data/models --out results.csv --no_gpu
```

## ğŸ“Š Output Format

### Transformer Analysis Output (CSV)
Contains the following fields:
- `model_path`: Model path
- `model_id`: Model identifier
- `revision`: Model version
- `param_name`: Parameter name
- `layer_index`: Layer index
- `block_type`: Module type (embedding/q_proj/k_proj/v_proj/o_proj/moe/output)
- `shape`: Parameter shape
- `rows`, `cols`: Number of rows and columns
- `design_rank`: Design rank
- `actual_rank`: Actual numerical rank
- `rank_ratio`: Rank ratio
- **`svd_90_percent_rank`**: Number of singular values corresponding to 90% variance (new feature)
- **`svd_90_percent_ratio`**: Ratio of 90% variance rank to design rank (new feature)
- `mean`, `std`, `var`: Statistics
- `sparsity`: Sparsity
- `dtype`: Data type
- `created_at`: Creation time

### Console Output Example
```
================================================================================
LAYER-BY-LAYER MATRIX ANALYSIS
================================================================================

ğŸ”¹ LAYER 0
--------------------------------------------------
  ğŸ“Š q_proj        | Shape: (512, 512)      | Rank: 128/512 (25.0%)
      SVD 90%:  64/512 (12.5%) | Sparsity: 10.0% | Î¼= 0.0000 Ïƒ= 0.1000
  ğŸ“Š k_proj        | Shape: (512, 512)      | Rank: 128/512 (25.0%)
      SVD 90%:  64/512 (12.5%) | Sparsity: 10.0% | Î¼= 0.0000 Ïƒ= 0.1000
```

## ğŸ”§ Script Descriptions

### transformer_analysis.py (recommended)
**New features**: SVD singular value analysis and GPU acceleration
- Analyze all transformer matrix parameters
- Calculate the number of singular values corresponding to 90% variance
- Support GPU acceleration for SVD calculations
- Format output of matrix information for each layer

**Parameters:**
- `--model_path`: Model path (required)
- `--out`: Output CSV file path (required)
- `--model_id`: Model ID (optional)
- `--revision`: Model version (optional)
- `--rank_k`: Maximum calculation rank (default: 128)
- `--no_gpu`: Disable GPU acceleration

### download.py
Model download script, supports:
- Download models from Hugging Face
- Specify version and branch
- Automatic cache management

**Parameters:**
- `--model_id`: Hugging Face model ID (required)
- `--out`: Output directory (required)
- `--revision`: Model version (optional)

### analyze.py
General parameter analysis script, supports:
- Automatic embedding weight recognition
- Calculate statistics and rank
- Multiple output formats

**Parameters:**
- `--model_path`: Model path (required)
- `--out`: Output file path (required)
- `--format`: Output format (csv/json) (optional)

### embedding_analysis.py
Specialized embedding layer analysis script, supports:
- K-means clustering analysis
- Elbow method to determine optimal number of clusters
- Result visualization

**Parameters:**
- `--model_path`: Model path (required)
- `--out`: Output file path (required)
- `--random_state`: Random seed (optional)

## ğŸ“ˆ Analysis Features

### SVD Singular Value Analysis (new feature)
- **90% Variance Analysis**: Calculate how many singular values can represent more than 90% of matrix variance
- **Compressibility Assessment**: Identify matrices that can be approximated with low rank
- **Performance Optimization**: Find computational bottlenecks and optimization opportunities

### Statistical Calculations
- **Shape Analysis**: Automatically identify parameter dimensions
- **Rank Analysis**: Calculate design rank vs actual rank of matrices
- **Statistical Features**: Mean, standard deviation, variance
- **Sparsity**: Calculate proportion of elements close to zero

### Module Classification
Automatically classify parameters as:
- `embedding`: Word embedding layer
- `q_proj`: Query projection layer
- `k_proj`: Key projection layer
- `v_proj`: Value projection layer
- `o_proj`: Output projection layer
- `moe`: Mixture of experts layer
- `norm`: Normalization layer
- `output`: Output layer

### Clustering Analysis
- Use elbow method to determine optimal number of clusters
- K-means clustering algorithm
- Result visualization

## ğŸ” Usage Examples

### Analyze Qwen3 model (recommended)
```bash
# Use GPU acceleration to analyze Qwen3 model
python scripts/transformer_analysis.py \
    --model_path data/models \
    --out data/outputs/qwen3_analysis.csv \
    --model_id "Qwen/Qwen3-4B" \
    --rank_k 512
```

### Analyze Llama-2 model
```bash
# Download model
python scripts/download.py --model_id meta-llama/Llama-2-7b-hf --out data/models/

# Use GPU acceleration analysis
python scripts/transformer_analysis.py --model_path data/models --out data/outputs/llama2_analysis.csv
```

## ğŸ› Troubleshooting

### Common Issues

1. **GPU Memory Insufficient**
   ```
   âš ï¸  GPU OOM, falling back to CPU for matrix (4096, 4096)
   ```
   **Solution**: 
   - Reduce `--rank_k` parameter value
   - Close other GPU applications
   - Use `--no_gpu` to force CPU mode

2. **CUDA Not Available**
   ```
   âŒ CUDA not available
   ```
   **Solution**:
   - Check NVIDIA driver installation
   - Verify PyTorch CUDA version
   - Confirm GPU hardware support

3. **Memory Insufficient**
   - Use `--low_cpu_mem_usage` parameter
   - Reduce precision (float16)
   - Process large models in batches

4. **Download Failure**
   - Check network connection
   - Use mirror sources
   - Retry download

5. **Unsupported Model Format**
   - Ensure model supports safetensors format
   - Check model structure

### Logging and Debugging
- All scripts output detailed log information
- Use `--verbose` parameter for more debug information

## ğŸ¤ Contributing

Welcome contributions of code and ideas! Please follow these principles:

1. **Plan First, Execute Later**: Write a minimum viable plan before starting each task
2. **Minimal Necessary Abstraction**: Keep code concise, avoid over-engineering
3. **Reproducibility**: Fix random seeds, record version and environment information
4. **Documentation**: Add documentation and examples for new features

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- Hugging Face team for providing the transformers library
- PyTorch team for providing the deep learning framework
- Open source community for support and contributions

## ğŸ“ Contact

For questions or suggestions, please contact us through:
- Submit Issues
- Send emails
- Participate in discussions

---

**Note**: This project is for research and learning purposes only. Please comply with the relevant model usage terms and licenses.

</div>

---

<div id="chinese">

# AI Block Research

ä¸€ä¸ªç”¨äºä¸‹è½½ã€è¯»å–å’Œåˆ†æå¤§è¯­è¨€æ¨¡å‹å‚æ•°çš„ç ”ç©¶å·¥å…·é›†ã€‚æœ¬é¡¹ç›®é€šè¿‡ä¸‹è½½ä¸è¯»å–å¤§æ¨¡å‹å‚æ•°ï¼Œå¹¶ç”¨ç»“æ„åŒ–åˆ†æï¼ˆembeddingã€å„å±‚çŸ©é˜µç»´åº¦ä¸ç§©ã€ç»Ÿè®¡é‡ç­‰ï¼‰ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

- **æ¨¡å‹ä¸‹è½½**: ä»Hugging Faceè‡ªåŠ¨ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶
- **å‚æ•°åˆ†æ**: åˆ†ææ¨¡å‹å‚æ•°çš„å½¢çŠ¶ã€ç§©ã€ç»Ÿè®¡é‡ç­‰
- **åµŒå…¥åˆ†æ**: ä¸“é—¨çš„embeddingå±‚åˆ†æï¼ŒåŒ…æ‹¬K-meansèšç±»
- **Transformeråˆ†æ**: åˆ†ætransformerå„å±‚çš„å‚æ•°ç‰¹æ€§ï¼ŒåŒ…æ‹¬SVDå¥‡å¼‚å€¼åˆ†æ
- **GPUåŠ é€Ÿ**: æ”¯æŒNVIDIA GPUåŠ é€Ÿå¤§å‹çŸ©é˜µçš„SVDè®¡ç®—
- **æ•°æ®å¯¼å‡º**: æ”¯æŒCSVã€JSONç­‰å¤šç§æ ¼å¼è¾“å‡º
- **å¯è§†åŒ–**: ç”Ÿæˆåˆ†æå›¾è¡¨å’Œç»Ÿè®¡æŠ¥å‘Š

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

- Python 3.10+
- æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: Linux, macOS, Windows
- æ¨èå†…å­˜: 8GB+ (å–å†³äºæ¨¡å‹å¤§å°)
- **GPUæ”¯æŒ**: NVIDIA GPU with CUDA support (æ¨èRTX 3080+)
- **æ˜¾å­˜**: è‡³å°‘8GB (æ¨è16GB+)

## ğŸ› ï¸ å®‰è£…

### 1. å…‹éš†é¡¹ç›®
```bash
git clone git@github.com:chenfengMeng2021/transformer_parameter_analysis.git
cd transformer_parameter_analysis
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# æˆ–
.venv\Scripts\activate     # Windows
```

### 3. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt

# å¦‚æœéœ€è¦GPUæ”¯æŒï¼Œå®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
transformer_parameter_analysis/
â”œâ”€â”€ data/                          # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ models/                    # æ¨¡å‹ç¼“å­˜ç›®å½•
â”‚   â””â”€â”€ outputs/                   # åˆ†æç»“æœè¾“å‡º
â”œâ”€â”€ scripts/                       # æ ¸å¿ƒè„šæœ¬
â”‚   â”œâ”€â”€ download.py               # æ¨¡å‹ä¸‹è½½è„šæœ¬
â”‚   â”œâ”€â”€ analyze.py                # å‚æ•°åˆ†æè„šæœ¬
â”‚   â”œâ”€â”€ embedding_analysis.py     # åµŒå…¥å±‚åˆ†æè„šæœ¬
â”‚   â””â”€â”€ transformer_analysis.py   # Transformeråˆ†æè„šæœ¬ï¼ˆæ”¯æŒGPUåŠ é€Ÿï¼‰
â”œâ”€â”€ requirements.txt               # Pythonä¾èµ–
â”œâ”€â”€ pyproject.toml                # é¡¹ç›®é…ç½®
â””â”€â”€ README.md                     # é¡¹ç›®è¯´æ˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä¸‹è½½æ¨¡å‹
```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
python scripts/download.py --model_id Qwen/Qwen3-4B --out data/models/
```

### 2. åˆ†ææ¨¡å‹å‚æ•°
```bash
# åˆ†ææ¨¡å‹å‚æ•°å¹¶å¯¼å‡ºä¸ºCSV
python scripts/analyze.py --model_path data/models/Qwen/Qwen3-4B --out data/outputs/params.csv --format csv
```

### 3. TransformerçŸ©é˜µåˆ†æï¼ˆæ¨èï¼‰
```bash
# ä½¿ç”¨GPUåŠ é€Ÿåˆ†ætransformerçŸ©é˜µ
python scripts/transformer_analysis.py --model_path data/models --out data/outputs/transformer_analysis.csv
```

### 4. åµŒå…¥å±‚åˆ†æ
```bash
# åˆ†æembeddingå±‚å¹¶è¿›è¡Œèšç±»
python scripts/embedding_analysis.py --model_path data/models/Qwen/Qwen3-4B --out data/outputs/embedding_analysis.csv
```

## ğŸš€ GPU åŠ é€ŸåŠŸèƒ½

### æ–°åŠŸèƒ½ç‰¹æ€§
- **å®Œæ•´çŸ©é˜µåˆ†æ**: ä¸å†éœ€è¦é‡‡æ ·ï¼Œåˆ†æå®Œæ•´çš„çŸ©é˜µå‚æ•°
- **CUDA åŠ é€Ÿ**: ä½¿ç”¨PyTorchçš„CUDAåç«¯åŠ é€ŸSVDè®¡ç®—
- **æ™ºèƒ½å†…å­˜ç®¡ç†**: è‡ªåŠ¨å¤„ç†GPUå†…å­˜ä¸è¶³çš„æƒ…å†µ
- **é™çº§ç­–ç•¥**: GPUå†…å­˜ä¸è¶³æ—¶è‡ªåŠ¨é™çº§åˆ°CPUè®¡ç®—

### GPU vs CPU æ€§èƒ½æå‡
| çŸ©é˜µå¤§å° | CPUæ—¶é—´ | GPUæ—¶é—´ | åŠ é€Ÿæ¯” |
|----------|---------|---------|--------|
| 512Ã—512  | ~0.5s   | ~0.1s   | 5x     |
| 1024Ã—1024| ~2s     | ~0.3s   | 7x     |
| 2048Ã—2048| ~8s     | ~1s     | 8x     |
| 4096Ã—4096| ~32s    | ~4s     | 8x     |

### GPUä½¿ç”¨æ–¹æ³•
```bash
# ä½¿ç”¨GPUåŠ é€Ÿåˆ†æï¼ˆé»˜è®¤ï¼‰
python scripts/transformer_analysis.py --model_path data/models --out results.csv

# å¼ºåˆ¶ä½¿ç”¨CPUåˆ†æ
python scripts/transformer_analysis.py --model_path data/models --out results.csv --no_gpu
```

## ğŸ“Š è¾“å‡ºæ ¼å¼

### Transformeråˆ†æè¾“å‡º (CSV)
åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- `model_path`: æ¨¡å‹è·¯å¾„
- `model_id`: æ¨¡å‹æ ‡è¯†ç¬¦
- `revision`: æ¨¡å‹ç‰ˆæœ¬
- `param_name`: å‚æ•°åç§°
- `layer_index`: å±‚ç´¢å¼•
- `block_type`: æ¨¡å—ç±»å‹ (embedding/q_proj/k_proj/v_proj/o_proj/moe/output)
- `shape`: å‚æ•°å½¢çŠ¶
- `rows`, `cols`: è¡Œæ•°å’Œåˆ—æ•°
- `design_rank`: è®¾è®¡ç§©
- `actual_rank`: å®é™…æ•°å€¼ç§©
- `rank_ratio`: ç§©æ¯”ä¾‹
- **`svd_90_percent_rank`**: 90%æ–¹å·®å¯¹åº”çš„å¥‡å¼‚å€¼æ•°é‡ï¼ˆæ–°åŠŸèƒ½ï¼‰
- **`svd_90_percent_ratio`**: 90%æ–¹å·®ç§©ä¸è®¾è®¡ç§©çš„æ¯”å€¼ï¼ˆæ–°åŠŸèƒ½ï¼‰
- `mean`, `std`, `var`: ç»Ÿè®¡é‡
- `sparsity`: ç¨€ç–åº¦
- `dtype`: æ•°æ®ç±»å‹
- `created_at`: åˆ›å»ºæ—¶é—´

### æ§åˆ¶å°è¾“å‡ºç¤ºä¾‹
```
================================================================================
LAYER-BY-LAYER MATRIX ANALYSIS
================================================================================

ğŸ”¹ LAYER 0
--------------------------------------------------
  ğŸ“Š q_proj        | Shape: (512, 512)      | Rank: 128/512 (25.0%)
      SVD 90%:  64/512 (12.5%) | Sparsity: 10.0% | Î¼= 0.0000 Ïƒ= 0.1000
  ğŸ“Š k_proj        | Shape: (512, 512)      | Rank: 128/512 (25.0%)
      SVD 90%:  64/512 (12.5%) | Sparsity: 10.0% | Î¼= 0.0000 Ïƒ= 0.1000
```

## ğŸ”§ è„šæœ¬è¯´æ˜

### transformer_analysis.pyï¼ˆæ¨èï¼‰
**æ–°å¢åŠŸèƒ½**: SVDå¥‡å¼‚å€¼åˆ†æå’ŒGPUåŠ é€Ÿ
- åˆ†ææ‰€æœ‰transformerçŸ©é˜µå‚æ•°
- è®¡ç®—90%æ–¹å·®å¯¹åº”çš„å¥‡å¼‚å€¼æ•°é‡
- æ”¯æŒGPUåŠ é€ŸSVDè®¡ç®—
- æ ¼å¼åŒ–è¾“å‡ºæ¯ä¸€å±‚çš„çŸ©é˜µä¿¡æ¯

**å‚æ•°:**
- `--model_path`: æ¨¡å‹è·¯å¾„ (å¿…éœ€)
- `--out`: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ (å¿…éœ€)
- `--model_id`: æ¨¡å‹ID (å¯é€‰)
- `--revision`: æ¨¡å‹ç‰ˆæœ¬ (å¯é€‰)
- `--rank_k`: æœ€å¤§è®¡ç®—ç§© (é»˜è®¤: 128)
- `--no_gpu`: ç¦ç”¨GPUåŠ é€Ÿ

### download.py
æ¨¡å‹ä¸‹è½½è„šæœ¬ï¼Œæ”¯æŒï¼š
- ä»Hugging Faceä¸‹è½½æ¨¡å‹
- æŒ‡å®šç‰ˆæœ¬å’Œåˆ†æ”¯
- è‡ªåŠ¨ç¼“å­˜ç®¡ç†

**å‚æ•°:**
- `--model_id`: Hugging Faceæ¨¡å‹ID (å¿…éœ€)
- `--out`: è¾“å‡ºç›®å½• (å¿…éœ€)
- `--revision`: æ¨¡å‹ç‰ˆæœ¬ (å¯é€‰)

### analyze.py
é€šç”¨å‚æ•°åˆ†æè„šæœ¬ï¼Œæ”¯æŒï¼š
- è‡ªåŠ¨è¯†åˆ«embeddingæƒé‡
- è®¡ç®—ç»Ÿè®¡é‡å’Œç§©
- å¤šç§è¾“å‡ºæ ¼å¼

**å‚æ•°:**
- `--model_path`: æ¨¡å‹è·¯å¾„ (å¿…éœ€)
- `--out`: è¾“å‡ºæ–‡ä»¶è·¯å¾„ (å¿…éœ€)
- `--format`: è¾“å‡ºæ ¼å¼ (csv/json) (å¯é€‰)

### embedding_analysis.py
ä¸“é—¨çš„embeddingå±‚åˆ†æè„šæœ¬ï¼Œæ”¯æŒï¼š
- K-meansèšç±»åˆ†æ
- è‚˜éƒ¨æ³•åˆ™ç¡®å®šæœ€ä¼˜èšç±»æ•°
- å¯è§†åŒ–ç»“æœ

**å‚æ•°:**
- `--model_path`: æ¨¡å‹è·¯å¾„ (å¿…éœ€)
- `--out`: è¾“å‡ºæ–‡ä»¶è·¯å¾„ (å¿…éœ€)
- `--random_state`: éšæœºç§å­ (å¯é€‰)

## ğŸ“ˆ åˆ†æç‰¹æ€§

### SVDå¥‡å¼‚å€¼åˆ†æï¼ˆæ–°åŠŸèƒ½ï¼‰
- **90%æ–¹å·®åˆ†æ**: è®¡ç®—å‰å¤šå°‘ä¸ªå¥‡å¼‚å€¼å¯ä»¥ä»£è¡¨è¶…è¿‡90%çš„çŸ©é˜µæ–¹å·®
- **å‹ç¼©æ€§è¯„ä¼°**: è¯†åˆ«å¯ä»¥ä½ç§©è¿‘ä¼¼çš„çŸ©é˜µ
- **æ€§èƒ½ä¼˜åŒ–**: æ‰¾åˆ°è®¡ç®—ç“¶é¢ˆå’Œä¼˜åŒ–æœºä¼š

### ç»Ÿè®¡é‡è®¡ç®—
- **å½¢çŠ¶åˆ†æ**: è‡ªåŠ¨è¯†åˆ«å‚æ•°ç»´åº¦
- **ç§©åˆ†æ**: è®¡ç®—çŸ©é˜µçš„è®¾è®¡ç§©vså®é™…ç§©
- **ç»Ÿè®¡ç‰¹å¾**: å‡å€¼ã€æ ‡å‡†å·®ã€æ–¹å·®
- **ç¨€ç–åº¦**: è®¡ç®—æ¥è¿‘é›¶çš„å…ƒç´ æ¯”ä¾‹

### æ¨¡å—åˆ†ç±»
è‡ªåŠ¨å°†å‚æ•°åˆ†ç±»ä¸ºï¼š
- `embedding`: è¯åµŒå…¥å±‚
- `q_proj`: QueryæŠ•å½±å±‚
- `k_proj`: KeyæŠ•å½±å±‚
- `v_proj`: ValueæŠ•å½±å±‚
- `o_proj`: è¾“å‡ºæŠ•å½±å±‚
- `moe`: æ··åˆä¸“å®¶å±‚
- `norm`: å½’ä¸€åŒ–å±‚
- `output`: è¾“å‡ºå±‚

### èšç±»åˆ†æ
- ä½¿ç”¨è‚˜éƒ¨æ³•åˆ™ç¡®å®šæœ€ä¼˜èšç±»æ•°
- K-meansèšç±»ç®—æ³•
- ç»“æœå¯è§†åŒ–

## ğŸ” ä½¿ç”¨ç¤ºä¾‹

### åˆ†æQwen3æ¨¡å‹ï¼ˆæ¨èï¼‰
```bash
# ä½¿ç”¨GPUåŠ é€Ÿåˆ†æQwen3æ¨¡å‹
python scripts/transformer_analysis.py \
    --model_path data/models \
    --out data/outputs/qwen3_analysis.csv \
    --model_id "Qwen/Qwen3-4B" \
    --rank_k 512
```

### åˆ†æLlama-2æ¨¡å‹
```bash
# ä¸‹è½½æ¨¡å‹
python scripts/download.py --model_id meta-llama/Llama-2-7b-hf --out data/models/

# ä½¿ç”¨GPUåŠ é€Ÿåˆ†æ
python scripts/transformer_analysis.py --model_path data/models --out data/outputs/llama2_analysis.csv
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **GPUå†…å­˜ä¸è¶³**
   ```
   âš ï¸  GPU OOM, falling back to CPU for matrix (4096, 4096)
   ```
   **è§£å†³æ–¹æ¡ˆ**: 
   - å‡å°‘ `--rank_k` å‚æ•°å€¼
   - å…³é—­å…¶ä»–GPUåº”ç”¨
   - ä½¿ç”¨ `--no_gpu` å¼ºåˆ¶CPUæ¨¡å¼

2. **CUDAä¸å¯ç”¨**
   ```
   âŒ CUDA not available
   ```
   **è§£å†³æ–¹æ¡ˆ**:
   - æ£€æŸ¥NVIDIAé©±åŠ¨å®‰è£…
   - éªŒè¯PyTorch CUDAç‰ˆæœ¬
   - ç¡®è®¤GPUç¡¬ä»¶æ”¯æŒ

3. **å†…å­˜ä¸è¶³**
   - ä½¿ç”¨`--low_cpu_mem_usage`å‚æ•°
   - é™ä½ç²¾åº¦ (float16)
   - åˆ†æ‰¹å¤„ç†å¤§æ¨¡å‹

4. **ä¸‹è½½å¤±è´¥**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - ä½¿ç”¨é•œåƒæº
   - é‡è¯•ä¸‹è½½

5. **æ¨¡å‹æ ¼å¼ä¸æ”¯æŒ**
   - ç¡®ä¿æ¨¡å‹æ”¯æŒsafetensorsæ ¼å¼
   - æ£€æŸ¥æ¨¡å‹ç»“æ„

### æ—¥å¿—å’Œè°ƒè¯•
- æ‰€æœ‰è„šæœ¬éƒ½ä¼šè¾“å‡ºè¯¦ç»†çš„æ—¥å¿—ä¿¡æ¯
- ä½¿ç”¨`--verbose`å‚æ•°è·å–æ›´å¤šè°ƒè¯•ä¿¡æ¯

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç å’Œæƒ³æ³•ï¼è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **å…ˆè®¡åˆ’ï¼Œåæ‰§è¡Œ**: æ¯ä¸ªä»»åŠ¡åœ¨åŠ¨æ‰‹å‰å†™å‡ºæœ€å°å¯è¡Œè®¡åˆ’
2. **æœ€å°å¿…è¦æŠ½è±¡**: ä¿æŒä»£ç ç®€æ´ï¼Œé¿å…è¿‡åº¦å·¥ç¨‹åŒ–
3. **å¯å¤ç°æ€§**: å›ºå®šéšæœºç§å­ï¼Œè®°å½•ç‰ˆæœ¬å’Œç¯å¢ƒä¿¡æ¯
4. **æ–‡æ¡£åŒ–**: ä¸ºæ–°å¢åŠŸèƒ½æ·»åŠ æ–‡æ¡£å’Œç¤ºä¾‹

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- Hugging Faceå›¢é˜Ÿæä¾›çš„transformersåº“
- PyTorchå›¢é˜Ÿæä¾›çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
- å¼€æºç¤¾åŒºçš„æ”¯æŒå’Œè´¡çŒ®

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤Issue
- å‘é€é‚®ä»¶
- å‚ä¸è®¨è®º

---

**æ³¨æ„**: æœ¬é¡¹ç›®ä»…ç”¨äºç ”ç©¶å’Œå­¦ä¹ ç›®çš„ï¼Œè¯·éµå®ˆç›¸å…³æ¨¡å‹çš„ä½¿ç”¨æ¡æ¬¾å’Œè®¸å¯è¯ã€‚

</div>
